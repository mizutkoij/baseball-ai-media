# 現実的な実行時間（アクセス制限回避版）

## サイト制限を考慮した安全な設定

### 礼儀正しいスクレイパーの設定

```python
# 安全重視の設定
MIN_INTERVAL_SEC = 15.0   # 最低15秒間隔
MAX_INTERVAL_SEC = 30.0   # 最大30秒間隔
BATCH_BREAK = 60.0        # 5ページ毎に1分休憩
MAX_RETRIES = 3           # リトライ回数
USER_AGENT_ROTATION = 5   # User-Agentローテーション
```

## 現実的な実行時間

### 基本データ収集（推奨）

| データセット | ページ数 | 平均間隔 | 休憩時間 | **合計時間** |
|-------------|----------|----------|----------|-------------|
| **ロスターのみ** | 12ページ | 22.5秒/ページ | 2回×60秒 | **7分** |
| **ロスター + 統計** | 16ページ | 22.5秒/ページ | 3回×60秒 | **9分** |
| **基本フルセット** | 20ページ | 22.5秒/ページ | 4回×60秒 | **12分** |

### 詳細データ収集（週次）

| データセット | ページ数 | 平均間隔 | 休憩時間 | **合計時間** |
|-------------|----------|----------|----------|-------------|
| **条件別統計込み** | 50ページ | 22.5秒/ページ | 10回×60秒 | **29分** |
| **フル詳細データ** | 100ページ | 22.5秒/ページ | 20回×60秒 | **58分** |

## 時間の内訳詳細

### 1ページあたりの処理時間
```
基本リクエスト:       1.0秒
レート制限待機:       15-30秒 (平均22.5秒)
データ解析:          0.5秒
CSV書き込み:         0.1秒
メモリ管理:          0.2秒
エラー処理余裕:       1.0秒
--------------------------------
合計:                ~25秒/ページ
```

### バッチ休憩の重要性
```
連続5ページ処理後:    60秒休憩
- サーバー負荷軽減
- IP制限回避
- セッション維持
```

## アクセス制限回避機能

### 1. レート制限対策
- **ランダム間隔**: 15-30秒でランダム化
- **指数バックオフ**: エラー時は倍々で待機時間増加
- **429/403対応**: 適切な待機とUser-Agent変更

### 2. セッション管理
- **Keep-Alive**: 接続維持でサーバー負荷軽減
- **適切なヘッダー**: ブラウザっぽいリクエスト
- **User-Agentローテーション**: 5種類でローテーション

### 3. 安全な並列処理なし
- **順次処理のみ**: 並列アクセスでの制限回避
- **1セッション**: 複数IPによる制限回避

## 実運用での推奨パターン

### 日次データ収集（毎日）
```bash
# 基本ロスター + 統計
python scripts/polite_scraper.py \
  --date $(date +%Y-%m-%d) \
  --targets roster,stats \
  --min-interval 15 \
  --max-interval 30
```
- **実行時間**: 9分
- **データ量**: ~400件
- **リスク**: 低

### 週次詳細収集（日曜日）
```bash
# 条件別統計含む
python scripts/polite_scraper.py \
  --date $(date +%Y-%m-%d) \
  --targets roster,stats,conditions \
  --min-interval 20 \
  --max-interval 35
```
- **実行時間**: 30分
- **データ量**: ~2,000件
- **リスク**: 中

### 月次アーカイブ（月初）
```bash
# フル詳細データ
python scripts/polite_scraper.py \
  --date $(date +%Y-%m-%d) \
  --targets roster,stats,conditions,detailed \
  --min-interval 25 \
  --max-interval 40
```
- **実行時間**: 60分
- **データ量**: ~5,000件
- **リスク**: 中-高

## 元の高速版との比較

| 項目 | 高速版 | 安全版 | 備考 |
|------|--------|--------|------|
| **ロスター取得** | 40秒 | **7分** | 制限回避で10倍時間 |
| **基本データ** | 50秒 | **9分** | でも確実に取得可能 |
| **フルデータ** | 2-3分 | **30-60分** | 大容量は時間かかる |
| **制限リスク** | 高 | **極低** | 安全性を重視 |

## 制限を受けた場合の対処

### 自動対処機能
```python
# 429 Too Many Requests
if response.status_code == 429:
    wait_time = int(response.headers.get('Retry-After', 60))
    time.sleep(wait_time)

# 403 Forbidden
if response.status_code == 403:
    # User-Agent変更 + 長時間待機
    change_user_agent()
    time.sleep(120)
```

### 手動対処
1. **IP変更**: VPN使用やプロキシ経由
2. **時間変更**: 深夜帯など負荷の少ない時間
3. **データ分割**: 複数日に分けて収集

## 運用スケジュール例

### 平日運用
```cron
# 毎日朝6時（9分実行）
0 6 * * 1-5 python scripts/polite_scraper.py --date $(date +%Y-%m-%d) --targets roster,stats
```

### 週末運用  
```cron
# 日曜深夜2時（30分実行）
0 2 * * 0 python scripts/polite_scraper.py --date $(date +%Y-%m-%d) --targets roster,stats,conditions
```

### 月次運用
```cron
# 月初深夜1時（60分実行）
0 1 1 * * python scripts/polite_scraper.py --date $(date +%Y-%m-%d) --targets roster,stats,conditions,detailed
```

## メリット・デメリット

### メリット ✅
- **制限回避**: IP制限・レート制限を確実に回避
- **安定性**: 長期運用でも安全
- **データ品質**: 確実にデータ取得
- **サイト負荷**: 相手サーバーに優しい

### デメリット ⚠️
- **実行時間**: 高速版の10-20倍の時間
- **リアルタイム性**: 即座のデータ取得は困難
- **運用コスト**: 長時間の監視が必要

## 結論

**制限回避を重視した現実的な実行時間**:
- **日次基本データ**: 9分（確実・安全）
- **週次詳細データ**: 30分（推奨）
- **月次フルデータ**: 60分（最大）

高速版（40秒-3分）は制限リスクが高いため、**安全版（9-60分）を推奨**します。

---

**重要**: サイトの利用規約とrobots.txtを必ず確認し、相手サーバーに負荷をかけない礼儀正しいスクレイピングを心がけましょう。